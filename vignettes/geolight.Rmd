---
title: "How to estimate position with light data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{How to estimate position with light data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE, 
  comment = "#>"
)
```

In this vignette, we will compute the probability map of the Great Reed Warbler (18IC) using light data. Note that there are no specific functions from this package for computing the proability map of light and most functions are from the `GeoLight` package loaded through [`GeoLocTools`](https://github.com/slisovski/GeoLocTools). 

## Setup

```{r setup}
library(GeoPressureR)
library(leaflet)
library(MASS)
library(raster)
```

Define basic information about calibration. The second calibration is so short (1 day), that we don't consider it here

```{r}
lon_calib <- 17.05	
lat_calib <- 48.9
tm_calib_1 <- c(as.POSIXct("2017-06-20"), as.POSIXct("2017-07-20"))
# tm_calib_2 <- c(as.POSIXct("2018-04-29"), as.POSIXct("2018-05-1"))
```

Read pam data

```{r}
pam_data = pam_read(pathname = system.file("extdata", package = "GeoPressureR"),
                    crop_start = "2017-06-20", crop_end = "2018-05-02")
```

## Twilight Annotation

The twilight annotation follow closely the [chapter 4 of the geolocation manual](https://geolocationmanual.vogelwarte.ch/twilight.html) with the addion of a manual editing through trainset.

Find the time of twilight and change the timezone to UTC
```{r}
twl <- find_twilights(pam_data$light, 
                     threshold = min(raw$Light[raw$Light>0]), # first light of the day
                     include = "2017-09-23 00:00:00 UTC" # Not sure why
                     )
attr(twl$twilight, "tzone") <- "UTC" 
```

But the manual editing is quite easy with trainset. The main adventage is that you can come back to it after running the rest of the analysis to improve the editing.

Read more about trainset in the vignette [How to label tracks](labeling_tracks.html#introduction-to-trainset). In this case, you can label the datapoint you want to delete with any label name (and leave the label empty (black dot) to keep the datapoint).

First write the csv file, then open it in trainset, edit on trainset and finally export the new csv file.

```{r, eval=F}
write.csv(
  data.frame(
    series = ifelse(twl$rise,"Rise","Set"),
    timestamp = strftime(twl$twilight, "%Y-%m-%dT00:00:00Z", tz = "UTC"),
    value = as.numeric(format(twl$twilight, "%H")) * 60 + as.numeric(format(twl$twilight, "%M")),
    label = ifelse(is.null(twl$delete), "", ifelse(twl$delete,'Delete',''))
  ),
  paste0(system.file("extdata", package = "GeoPressureR"), "/18LX_light.csv"),
  row.names = FALSE
)
browseURL("https://trainset.geocene.com/")
```

Read the exported csv file and update the `Deleted` field in `twl`

```{r}
csv <- read.csv( paste0(system.file("extdata", package = "GeoPressureR"), "/18LX_light-labeled.csv"))
twl$deleted = !csv$label==""
```

We can visualize the final annotated twilight.

```{r, eval=F}
offset <- 12
lightImage( tagdata = raw,
            offset = offset,     
            zlim = c(0, 4))

tsimagePoints(twl$twilight, offset = offset, pch = 16, cex = 1.2,
              col = ifelse(twl$Deleted, "grey20", ifelse(twl$Rise, "firebrick", "cornflowerblue")))

tsimageDeploymentLines(twl$twilight, lon_calib, lat_calib, offset = offset,
                       lwd = 2, col = adjustcolor("orange", alpha.f = 0.8))

abline(v = tm_calib_1, lty = c(1,2), col = "firebrick", lwd = 1.5)
#abline(v = tm_calib_2, lty = c(1,2), col = "firebrick", lwd = 1.5)
```

## Calibration

Instead of calibrating the twilights in term of duration, we model the zenith angle error.

First, get the twilight during the calibration period
```{r}
twl_calib <- subset(twl, !deleted & twilight>=tm_calib_1[1] & twilight<=tm_calib_1[2])
```

We compute the zenith angle (i.e., elevation of the sun) of the time of the twilights at calibration site.  We fit a simple gamma distribution.

```{r}
sun <- solar(twl_calib$twilight)
z = refracted(zenith(sun, lon_calib, lat_calib)) 
fitE = fitdistr(z,"gamma")
hist(z, freq=F)
z.axes = seq(90,100,0.1)
lines(z.axes, dgamma(z.axes, fitE$estimate["shape"], fitE$estimate["rate"]), col="red")
```

## Stationary period

Before computing the probability map, we group the twilights by stationary periods using the activity data. You can learn more about this step in [How to use GeoPressureR](using-geopressurer.html#identifying-stationary-periods)

```{r}
pam_data = trainset_read(pam_data, pathname=system.file("extdata", package = "GeoPressureR"))
pam_data = pam_sta(pam_data)
twilight_sta_id <- sapply(twl$twilight, function(x) which(pam_data$sta$start < x & x < pam_data$sta$end))
twilight_sta_id[sapply(twilight_sta_id, function(x) length(x) == 0)] <- 0
twl$sta_id <- unlist(twilight_sta_id)
```

## Proability map

We first define a grid on which to compute the probabilities
```{r}
data("prob_map_list", package = "GeoPressureR")
g <- as.data.frame(prob_map_list[[1]], xy=TRUE)
g$layer=NA
```

The, selecting only the twilight not labeled as deleted, we compute the probability of observing the zenith angle of each twilights using the calibrated error function for each grid cell. 

```{r}
twl.clean <- subset(twl, !deleted)
sun <- solar(twl.clean$twilight)
pgz = apply(g,1, function(x) {
    z = refracted(zenith(sun, x[1], x[2])) 
    dgamma(z, fitE$estimate["shape"], fitE$estimate["rate"])
  })
```

Aggregating the probability map of each twilight per stationary periods required some assumption on the independance/correlation of the twilight errors.
Here we use a log-linear pooling with a weight of $w=0.1$,

```{r}
w=0.1
```

We loop through each stationary period and create a raster map with the aggregated probabilities

```{r}
raster_light_list <- c()
for (i_s in seq_len(nrow(pam_data$sta))){
  id = twl.clean$sta_id==pam_data$sta$sta_id[i_s]
  if (sum(id)>1){
    g$layer = exp(colSums(w*log(pgz[id,]))) # Log-linear equation express in log 
  } else if(sum(id)==1) {
    g$layer = pgz[id,]
  } else {
    g$layer = 1
  }
  gr <- rasterFromXYZ(g)
  crs(gr) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
  metadata(gr) <- list(
        sta_id = pam_data$sta$sta_id[i_s],
        nb_sample = sum(id)
      )
  raster_light_list[[i_s]] <- gr
}
```

We can finally visualize the probability map for each stationary period

```{r, warning=F}
li_s=list()
l = leaflet() %>% addTiles() 
for (i_r in 1:length(raster_light_list)){
  i_s = metadata(raster_light_list[[i_r]])$sta_id
  info = pam_data$sta[pam_data$sta$sta_id==i_s,]
  info_str = paste0(i_s," | ",info$start,"->",info$end)
  li_s <- append(li_s, info_str)
  l = l %>% addRasterImage(raster_light_list[[i_r]], opacity = 0.8, group=info_str) 
}
l %>% 
  addCircles(lng=lon_calib,lat=lat_calib,color = "white", opacity=1) %>% 
  addLayersControl(
    overlayGroups = li_s,
    options = layersControlOptions(collapsed = FALSE)
  ) %>% hideGroup(tail(li_s,length(li_s)-1))
```

Export the data generated

```{r, eval=F}
usethis::use_data(raster_light_list, overwrite=T)
```

