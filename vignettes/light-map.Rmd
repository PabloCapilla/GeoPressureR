---
title: "Creating probability maps from light data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Creating probability maps from light data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  comment = "#>"
)
```

In this vignette, we use light data to estimate the position of the Great Reed Warbler (18IC) at each stationary period. A more thorough introduction to geolocation with light data can be found on <https://geolocationmanual.vogelwarte.ch/>.

## Setup

```{r setup, message=F}
library(GeoPressureR)
library(leaflet)
library(leaflet.extras)
library(MASS)
library(raster)
load(system.file("extdata", "18LX_pressure_prob.rda", package = "GeoPressureR"))
```

The `GeoLocTools` package will install a bunch of other R package for light analysis. We only use it for making nice figures. The code to compute the light position is included in `GeoPressureR`. [I can't make it work with pkgdown](https://github.com/Rafnuss/GeoPressureR/issues/13), so I am not going to use it in this vignette, but I still provides the code for the figure.

```{r, eval=F}
library(GeoLocTools)
setupGeolocation()
```

We can start by read the pam data retrieved from the geolocator.

```{r}
pam_data <- pam_read(
  pathname = system.file("extdata", package = "GeoPressureR"),
  crop_start = "2017-06-20", crop_end = "2018-05-02"
)
pam_data <- trainset_read(pam_data, pathname = system.file("extdata", package = "GeoPressureR"))
pam_data <- pam_sta(pam_data)
```

And define basic information about the calibration period and location. The second calibration is so short (1 day) that we discard it in this example.

```{r}
lon_calib <- 17.05
lat_calib <- 48.9
tm_calib_1 <- c(pam_data$sta$start[1], pam_data$sta$end[1])
# tm_calib_2 <- c(pam_data$sta$start[nrow(pam_data$sta)], pam_data$sta$end[nrow(pam_data$sta)])
```

## Twilight Annotation

To find the time of twilight, we can use `find_twilights()`, a function performing the same task than `TwGeos::FindTwilight()`, but differently. By default, the threshold is the first and last of light day. The `shift_k` argument is identical to the `offset` in `GeoLight` functions. By default, it will estimate it base on centering the nights. 

```{r}
shift_k <- 0
twl <- find_twilights(pam_data$light, shift_k = shift_k)
```

We can visualize the twilight

```{r, eval=F}
raw_geolight <- data.frame(
  Date = pam_data$light$date,
  Light = pam_data$light$obs
)
lightImage(
  tagdata = raw_geolight,
  offset = shift_k / 60 / 60
)
tsimagePoints(twl$twilight, offset = 0, pch = 16, cex = 1.2)
tsimageDeploymentLines(raw_geolight$Date,
  lon = lon_calib, lat = lat_calib,
  offset = shift_k / 60 / 60, lwd = 3, col = adjustcolor("orange", alpha.f = 0.5)
)

abline(v = tm_calib_1, lty = c(1, 2), col = "firebrick", lwd = 1.5)
```

![](light-map-1.png)
If the centering of the night is not correct, specify manually `shift_k`.

The manual editing is easily performed with TRAINSET. In this case, we must label the datapoints we want to delete with any label name. Read more about TRAINSET labelling in the dedicated vignette: [Labelling tracks](labelling-tracks.html).

We write the twilight data on a `csv` file which can be opened and edited in TRAINSET.

```{r, eval=F}
write.csv(
  data.frame(
    series = ifelse(twl$rise, "Rise", "Set"),
    timestamp = strftime(twl$twilight, "%Y-%m-%dT00:00:00Z", tz = "UTC"),
    value = as.numeric(format(twl$twilight, "%H")) * 60 + as.numeric(format(twl$twilight, "%M")),
    label = ifelse(is.null(twl$delete), "", ifelse(twl$delete, "Delete", ""))
  ),
  file = "~/18LX_light.csv",
  row.names = FALSE
)
browseURL("https://trainset.geocene.com/")
```

When the labeling is finished, export the file and update the `deleted` field in `twl`.

```{r}
csv <- read.csv(paste0(system.file("extdata", package = "GeoPressureR"), "/18LX_light-labeled.csv"))
twl$deleted <- !csv$label == ""
```

```{r, eval=F}
lightImage(tagdata = raw_geolight, offset = 0)
tsimagePoints(twl$twilight,
  offset = 0, pch = 16, cex = 1.2,
  col = ifelse(twl$deleted, "grey20", ifelse(twl$rise, "firebrick", "cornflowerblue"))
)
abline(v = tm_calib_1, lty = c(1, 2), col = "firebrick", lwd = 1.5)
```
![](light-map-2.png)

## Calibration

Instead of calibrating the twilight errors in terms of duration, we directly model the zenith angle error.

First, we retrieve the twilight during the calibration period.

```{r}
twl_calib <- subset(twl, !deleted & twilight >= tm_calib_1[1] & twilight <= tm_calib_1[2])
```

We then compute the zenith angle (i.e., elevation of the sun) of the twilight time at the calibration site.

```{r}
sun <- solar(twl_calib$twilight)
z <- refracted(zenith(sun, lon_calib, lat_calib))
```

Finally, we fit a kernel distribution for a relatively smooth bandwidth to account for possible bias.

```{r}
fit_z <- density(z, adjust=1.4, from = 60, to = 120)
hist(z, freq = F)
lines(fit_z, col = "red")
```

## Stationary period

Before computing the probability map, we group the twilights by stationary period using activity data. Learn more about this step in the vignette [Pressure Map](pressure-map.html#identifying-stationary-periods).

```{r}
tmp <- which(mapply(function(start, end) {
  start < twl$twilight & twl$twilight < end
}, pam_data$sta$start, pam_data$sta$end), arr.ind = TRUE)
twl$sta_id <- 0
twl$sta_id[tmp[, 1]] <- tmp[, 2]
```

## Probability map

We first define a grid on which to compute the probabilities. For ease of comparison with the pressure-derived map, we load the grid size and resolution from `pressure_prob` (computed with the vignette [Pressure Map](pressure-map.html#computing-the-map-of-pressure))

```{r}
g <- as.data.frame(pressure_prob[[1]], xy = TRUE)
g$layer <- NA
```

Selecting only the unlabelled twilights, we compute the probability of observing the zenith angle of each twilight using the calibrated error function for each grid cell.

```{r}
twl_clean <- subset(twl, !deleted)
sun <- solar(twl_clean$twilight)
pgz <- apply(g, 1, function(x) {
  z <- refracted(zenith(sun, x[1], x[2]))
  approx(fit_z$x, fit_z$y, z, yleft=0, yright = 0)$y
})
```

Aggregating the probability map of each twilight per stationary period requires some assumptions on the independence/correlation of the twilight errors. Read more about this in the vignette [Probability-aggregation](probability-aggregation.html)). Here, we use a log-linear pooling with a weight of $w=0.05$,

```{r}
w <- 0.05
```

We loop through each stationary period and create a raster map with the aggregated probabilities.

```{r}
light_prob <- c()
for (i_s in seq_len(nrow(pam_data$sta))) {
  id <- twl_clean$sta_id == pam_data$sta$sta_id[i_s]
  if (sum(id) > 1) {
    g$layer <- exp(colSums(w * log(pgz[id, ]))) # Log-linear equation express in log
  } else if (sum(id) == 1) {
    g$layer <- pgz[id, ]
  } else {
    g$layer <- 1
  }
  gr <- rasterFromXYZ(g)
  crs(gr) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
  metadata(gr) <- list(
    sta_id = pam_data$sta$sta_id[i_s],
    nb_sample = sum(id)
  )
  light_prob[[i_s]] <- gr
}
```

Finally, we can visualize the probability map for each stationary period.

```{r, warning=F}
li_s <- list()
l <- leaflet(width = "100%") %>%
  addProviderTiles(providers$Stamen.TerrainBackground) %>%
  addFullscreenControl()
for (i_r in seq_len(length(light_prob))) {
  i_s <- metadata(light_prob[[i_r]])$sta_id
  info <- pam_data$sta[pam_data$sta$sta_id == i_s, ]
  info_str <- paste0(i_s, " | ", info$start, "->", info$end)
  li_s <- append(li_s, info_str)
  l <- l %>% addRasterImage(light_prob[[i_r]], opacity = 0.8, colors = "OrRd", group = info_str)
}
l %>%
  addCircles(lng = lon_calib, lat = lat_calib, color = "black", opacity = 1) %>%
  addLayersControl(
    overlayGroups = li_s,
    options = layersControlOptions(collapsed = FALSE)
  ) %>%
  hideGroup(tail(li_s, length(li_s) - 1))
```
